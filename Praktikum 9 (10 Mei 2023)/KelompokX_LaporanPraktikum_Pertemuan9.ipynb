{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Bti47sRPwXaD"
      },
      "source": [
        "<a class=\"anchor\" id=\"0\"></a>\n",
        "# Random Forest Classifier with Feature Importance\n",
        "\n",
        "\n",
        "**Tugas Laporan Praktikum Pertemuan 9**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qLOJsR0vwXaF"
      },
      "source": [
        "## 1. Task Description <a class=\"anchor\" id=\"1\"></a>\n",
        "\n",
        "Please find another dataset that include **Time Series**. Do the same thing as what we tried in the 9th simulation.\n",
        "\n",
        "Bonus: If you can visualize with Decision Tree, please put it to the bottom after Classification Report (Last Part)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fJJk4SxOXnvN"
      },
      "source": [
        "*Nb: This file is the template for your 9th simulation, because some of code are still missing, you can see your simulation worksheet to help your code in this notebook. Also, you can re-edit or add the code to fit your dataset. But don't re-edit sub-chapter's name or even delete them (this is prohibited).*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ-ACnc7wXaG"
      },
      "source": [
        "## 2. Import libraries <a class=\"anchor\" id=\"2\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kj-Ey2uawXaG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "!pip install category-encoders\n",
        "\n",
        "sns.set(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIy8sxNhwXaH"
      },
      "source": [
        "## 3. Import dataset <a class=\"anchor\" id=\"3\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CqyfmC0wXaI"
      },
      "outputs": [],
      "source": [
        "data = ''\n",
        "\n",
        "df = pd.read_(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQC1KAgkwXaI"
      },
      "source": [
        "## 4. Exploratory data analysis <a class=\"anchor\" id=\"4\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoRJgek2wXaI"
      },
      "source": [
        "### 4.1  View dimensions of dataset <a class=\"anchor\" id=\"4.1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m9N4iucwXaI"
      },
      "outputs": [],
      "source": [
        "# print the shape\n",
        "print('The shape of the dataset : ', df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvAmHOJTwXaI"
      },
      "source": [
        "### 4.2 Preview the dataset <a class=\"anchor\" id=\"4.2\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU-r0saSwXaI",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOfn06eHwXaJ"
      },
      "source": [
        "### 4.3 Rename column names <a class=\"anchor\" id=\"4.3\"></a>\n",
        "\n",
        "We can see that the dataset does not have proper column names. The column names contain underscore. We should give proper names to the columns. We will do it as follows:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4ga5kHPwXaJ"
      },
      "outputs": [],
      "source": [
        "col_names = []\n",
        "\n",
        "df.columns = col_names\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enI74dZXwXaJ"
      },
      "source": [
        "### 4.4 View summary of dataset <a class=\"anchor\" id=\"4.4\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9mR9jYvwXaJ"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYIRs9MdwXaJ"
      },
      "source": [
        "### 4.5 Check the data types of columns <a class=\"anchor\" id=\"4.5\"></a>\n",
        "\n",
        "- The above `df.info()` command gives us the number of filled values along with the data types of columns.\n",
        "\n",
        "- If we simply want to check the data type of a particular column, we can use the following command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8ymQMzgwXaJ"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4zBeRvvwXaK"
      },
      "source": [
        "### 4.6 View statistical properties of dataset <a class=\"anchor\" id=\"4.6\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJDMTriiwXaK"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6DtauxGwXaK"
      },
      "source": [
        "- The above `df.describe()` command presents statistical properties in vertical form.\n",
        "\n",
        "- If we want to view the statistical properties in horizontal form, we should run the following command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwTKlrzhwXaK"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBOKM4dBwXaK"
      },
      "source": [
        "We can see that the above `df.describe().T` command presents statistical properties in horizontal form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvALONaOwXaK"
      },
      "source": [
        "#### Important points to note\n",
        "\n",
        "\n",
        "- The above command `df.describe()` helps us to view the statistical properties of numerical variables. It excludes character variables.\n",
        "\n",
        "- If we want to view the statistical properties of character variables, we should run the following command -\n",
        "\n",
        "        `df.describe(include=['object'])`\n",
        "\n",
        "- If we want to view the statistical properties of all the variables, we should run the following command -\n",
        "\n",
        "        `df.describe(include='all')`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXbBf5GtwXaL"
      },
      "outputs": [],
      "source": [
        "df.describe(include='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnKWVikbwXaL"
      },
      "source": [
        "### 4.7 Check for missing values <a class=\"anchor\" id=\"4.7\"></a>\n",
        "\n",
        "\n",
        "- In Python missing data is represented by two values:\n",
        "\n",
        "   - **None** : None is a Python singleton object that is often used for missing data in Python code.\n",
        "\n",
        "   - **NaN** : NaN is an acronym for Not a Number. It is a special floating-point value recognized by all systems   that use the standard IEEE floating-point representation.\n",
        "\n",
        "- There are different methods in place on how to detect missing values.\n",
        "\n",
        "\n",
        "#### Pandas isnull() and notnull() functions \n",
        "\n",
        "- Pandas offers two functions to test for missing values - **isnull()** and **notnull()**. \n",
        "\n",
        "- These are simple functions that return a boolean value indicating whether the passed in argument value is in fact missing data.\n",
        "\n",
        "\n",
        "Below, We will list some useful commands to deal with missing values.\n",
        "\n",
        "\n",
        "#### Useful commands to detect missing values \n",
        "\n",
        "- **df.isnull()**\n",
        "\n",
        "The above command checks whether each cell in a dataframe contains missing values or not. If the cell contains missing value, it returns True otherwise it returns False.\n",
        "\n",
        "- **df.isnull().sum()**\n",
        "\n",
        "The above command returns total number of missing values in each column in the dataframe.\n",
        "\n",
        "- **df.isnull().sum().sum()**\n",
        "\n",
        "It returns total number of missing values in the dataframe.\n",
        "\n",
        "\n",
        "- **df.isnull().mean()**\n",
        "\n",
        "It returns percentage of missing values in each column in the dataframe.\n",
        "\n",
        "\n",
        "- **df.isnull().any()**\n",
        "\n",
        "It checks which column has null values and which has not. The columns which has null values returns TRUE and FALSE otherwise.\n",
        "\n",
        "- **df.isnull().any().any()**\n",
        "\n",
        "It returns a boolean value indicating whether the dataframe has missing values or not. If dataframe contains missing values it returns TRUE and FALSE otherwise.\n",
        "\n",
        "- **df.isnull().values.any()**\n",
        "\n",
        "It checks whether a particular column has missing values or not. If the column contains missing values, then it returns TRUE otherwise FALSE.\n",
        "\n",
        "- **df.isnull().values.sum()**\n",
        "\n",
        "It returns the total number of missing values in the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i40fF9pJwXaL"
      },
      "outputs": [],
      "source": [
        "# check for missing values\n",
        "df..sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k5EtMs_1wXaM"
      },
      "source": [
        "### 4.8 Functional approach to EDA <a class=\"anchor\" id=\"4.9\"></a>\n",
        "\n",
        "- An alternative approach to EDA is to write a function that presents initial EDA of dataset.\n",
        "\n",
        "- We can write such a function as follows :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdopOFn4wXaM"
      },
      "outputs": [],
      "source": [
        "def initial_eda(df):\n",
        "    if isinstance(df, pd.DataFrame):\n",
        "        total_na = df.isna().sum().sum()\n",
        "        print(\"Dimensions : %d rows, %d columns\" % (df.shape[0], df.shape[1]))\n",
        "        print(\"Total NA Values : %d \" % (total_na))\n",
        "        print(\"%38s %10s     %10s %10s\" % (\"Column Name\", \"Data Type\", \"#Distinct\", \"NA Values\"))\n",
        "        col_name = df.columns\n",
        "        dtyp = df.dtypes\n",
        "        uniq = df.nunique()\n",
        "        na_val = df.isna().sum()\n",
        "        for i in range(len(df.columns)):\n",
        "            print(\"%38s %10s   %10s %10s\" % (col_name[i], dtyp[i], uniq[i], na_val[i]))\n",
        "        \n",
        "    else:\n",
        "        print(\"Expect a DataFrame but got a %15s\" % (type(df)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFSNM8ggwXaM"
      },
      "outputs": [],
      "source": [
        "initial_eda(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSsDoyeywXaf"
      },
      "source": [
        "### Types of variables\n",
        "\n",
        "- In this section, We segregate the dataset into categorical and numerical variables. \n",
        "\n",
        "- There are a mixture of categorical and numerical variables in the dataset. \n",
        "\n",
        "- Categorical variables have data type object. Numerical variables have data type int64.\n",
        "\n",
        "- First of all, We will explore categorical variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRkN5wblwXaf"
      },
      "source": [
        "## 5. Explore Categorical Variables <a class=\"anchor\" id=\"5\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujgC7rbxwXaf"
      },
      "source": [
        "### 5.1 Find categorical variables "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWmUdwUwwXaf"
      },
      "outputs": [],
      "source": [
        "categorical = [var for var in df.columns if df[var].dtype]\n",
        "\n",
        "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
        "\n",
        "print('The categorical variables are :\\n\\n', categorical)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCjGoNkXwXag"
      },
      "source": [
        "### 5.2 Preview categorical variables "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD3rEvX6wXag"
      },
      "outputs": [],
      "source": [
        "df[].head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5LB7mR6bwXag"
      },
      "source": [
        "### 5.3 Frequency distribution of categorical variables \n",
        "\n",
        "Now, we will check the frequency distribution of categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwsdwL9IwXag"
      },
      "outputs": [],
      "source": [
        "for var in categorical: \n",
        "    \n",
        "    print(df[].value_counts())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FASlmm5PwXag"
      },
      "source": [
        "### 5.4 Percentage of frequency distribution of values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "te_w4fLZwXah"
      },
      "outputs": [],
      "source": [
        "for var in categorical:\n",
        "    \n",
        "     print(df[].value_counts()/np.float(len()))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vBrf4Bh7wXah"
      },
      "source": [
        "### 5.5 Explore the variables "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "loOBNR_mwXah"
      },
      "source": [
        "#### Explore target variable "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcOIM5HJwXah"
      },
      "outputs": [],
      "source": [
        "# check for missing values\n",
        "\n",
        "df[''].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "celvolcbwXah"
      },
      "outputs": [],
      "source": [
        "# view number of unique values\n",
        "\n",
        "df[''].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0i2X5ibbwXai"
      },
      "outputs": [],
      "source": [
        "# view the unique values\n",
        "\n",
        "df[''].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X3ubPFDwXai"
      },
      "outputs": [],
      "source": [
        "# view the frequency distribution of values\n",
        "\n",
        "df[''].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWznPQ2_wXai"
      },
      "outputs": [],
      "source": [
        "# view percentage of frequency distribution of values\n",
        "\n",
        "df[''].value_counts()/len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cz_wJjKwXai"
      },
      "outputs": [],
      "source": [
        "# visualize frequency distribution of ... variable\n",
        "\n",
        "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
        "\n",
        "ax[0] = df[''].value_counts().plot.pie(explode=[0,0],autopct='%1.1f%%',ax=ax[0],shadow=True)\n",
        "ax[0].set_title('')\n",
        "\n",
        "\n",
        "#f, ax = plt.subplots(figsize=(6, 8))\n",
        "ax[1] = sns.countplot(x=\"\", data=df, palette=\"Set1\")\n",
        "ax[1].set_title(\"Frequency distribution of ... variable\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM8-fFTWwXaj"
      },
      "source": [
        "We can plot the bars horizontally as follows :-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOFKofM0wXaj"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(8, 6))\n",
        "ax = sns.countplot(y=\"\", data=df, palette=\"Set1\")\n",
        "ax.set_title(\"Frequency distribution of ...\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_9H_ScLwXaj"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "ax = sns.countplot(x=\"\", hue=\"\", data=df, palette=\"Set1\")\n",
        "ax.set_title(\"Frequency distribution of ...\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W6X6O3FhwXam"
      },
      "source": [
        "#### Explore *`another`* variable\n",
        "\n",
        "You can repeat this step, based on the variable that you think need to explore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOojBCOrwXam"
      },
      "outputs": [],
      "source": [
        "# check number of unique labels\n",
        "\n",
        "df..nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRoY4csRwXam"
      },
      "outputs": [],
      "source": [
        "# view unique labels\n",
        "\n",
        "df..()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxfuCyEGwXan"
      },
      "outputs": [],
      "source": [
        "# view frequency distribution of values\n",
        "\n",
        "df..value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYERemrCwXan"
      },
      "outputs": [],
      "source": [
        "# replace '?' values in ... variable with `NaN`\n",
        "\n",
        "df[''].replace(' ?', np.NaN, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVBBlRkZwXan"
      },
      "outputs": [],
      "source": [
        "# again check the frequency distribution of values\n",
        "\n",
        "df..value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8o9vDcWJwXan"
      },
      "outputs": [],
      "source": [
        "# visualize frequency distribution of `...` variable\n",
        "\n",
        "f, ax = plt.subplots(figsize=(12, 8))\n",
        "ax = sns.countplot(x=\"\", data=df, palette=\"Set1\")\n",
        "ax.set_title(\"Frequency distribution of ... variable\")\n",
        "ax.set_xticklabels(df..value_counts().index, rotation=30)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D7xt4Q5ywXap"
      },
      "source": [
        "### 5.6 Check missing values in categorical variables "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIeaRmWWwXas"
      },
      "outputs": [],
      "source": [
        "df[categorical].isnull().sum()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LktTPOXCwXas"
      },
      "source": [
        "### 5.7 Number of labels: Cardinality \n",
        "\n",
        "- The number of labels within a categorical variable is known as **cardinality**. \n",
        "\n",
        "- A high number of labels within a variable is known as **high cardinality**. \n",
        "\n",
        "- High cardinality may pose some serious problems in the machine learning model. So, We will check for high cardinality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANzml4rBwXas"
      },
      "outputs": [],
      "source": [
        "# check for cardinality in categorical variables\n",
        "\n",
        "for var in categorical:\n",
        "    \n",
        "    print(var, ' contains ', len(df[var].unique()), ' labels')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg9zVkpswXas"
      },
      "source": [
        "We can see that native_country column contains relatively large number of labels as compared to other columns. We will check for cardinality after train-test split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSapMTujwXas"
      },
      "source": [
        "## 6. Explore Numerical Variables <a class=\"anchor\" id=\"6\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9naPZj7qwXat"
      },
      "source": [
        "### 6.1  Find numerical variables "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjyCOOzKwXat"
      },
      "outputs": [],
      "source": [
        "numerical = [var for var in df.columns if df[var].dtype]\n",
        "\n",
        "print('There are {} numerical variables\\n'.format(len(numerical)))\n",
        "\n",
        "print('The numerical variables are :\\n\\n', numerical)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj5Z0qYhwXat"
      },
      "source": [
        "### 6.2 Preview the numerical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V93Yg0DUwXat"
      },
      "outputs": [],
      "source": [
        "df[].head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XUhH038HwXat"
      },
      "source": [
        "### 6.3 Check missing values in numerical variables "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-gYXDkhwXat"
      },
      "outputs": [],
      "source": [
        "df[numerical].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpugEN-UwXau"
      },
      "source": [
        "We can see that there are no missing values in the numerical variables."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oDmR9yXTwXau"
      },
      "source": [
        "### 6.4 Explore numerical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa4zgllPwXay"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsvvszCfwXay"
      },
      "source": [
        "## 7. Declare feature vector and target variable <a class=\"anchor\" id=\"7\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h8RDp4VwXay"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['...'], axis=1)\n",
        "\n",
        "y = df['']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuDkBwoVwXay"
      },
      "source": [
        "## 8. Split data into separate training and test set <a class=\"anchor\" id=\"8\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl2sMyJ-wXay"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = _split(X, y, test_size = 0.3, random_state = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ascceu1_wXay"
      },
      "outputs": [],
      "source": [
        "# check the shape of X_train and X_test\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_tH0mFBwXay"
      },
      "source": [
        "## 9. Feature Engineering  <a class=\"anchor\" id=\"9\"></a>\n",
        "**Feature Engineering** is the process of transforming raw data into useful features that help us to understand our model better and increase its predictive power. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMQ_xXZJwXay"
      },
      "source": [
        "### 9.1 Display categorical variables in training set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-bhJSz6wXay"
      },
      "outputs": [],
      "source": [
        "categorical = [col for col in X_train. if X_train[col].dtypes ]\n",
        "\n",
        "categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ9jfCcUwXaz"
      },
      "source": [
        "### 9.2 Display numerical variables in training set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtQJbfAPwXaz"
      },
      "outputs": [],
      "source": [
        "numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n",
        "\n",
        "numerical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3N2Qq6OwXaz"
      },
      "source": [
        "### 9.3 Engineering missing values in categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ16ov8twXaz"
      },
      "outputs": [],
      "source": [
        "# print percentage of missing values in the categorical variables in training set\n",
        "\n",
        "X_train[categorical].isnull().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkKynBRgwXaz"
      },
      "outputs": [],
      "source": [
        "# print categorical variables with missing data\n",
        "\n",
        "for col in categorical:\n",
        "    if X_train[col].isnull().mean()>0:\n",
        "        print(col, (X_train[col].isnull().mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQD6glgrwXaz"
      },
      "outputs": [],
      "source": [
        "# impute missing categorical variables with most frequent value\n",
        "\n",
        "for  in [X_train, X_test]:\n",
        "    # YOUR CODE HERE   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C97WYRQDwXa0"
      },
      "outputs": [],
      "source": [
        "# check missing values in categorical variables in X_train\n",
        "\n",
        "X_train[categorical].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJTYwv3dwXa0"
      },
      "outputs": [],
      "source": [
        "# check missing values in categorical variables in X_test\n",
        "\n",
        "X_test[categorical].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPXbOkdEwXa0"
      },
      "source": [
        "As a final check, We will check for missing values in X_train and X_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVRPqEhIwXa0"
      },
      "outputs": [],
      "source": [
        "# check missing values in X_train\n",
        "\n",
        "X_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vdRjDyZwXa0"
      },
      "outputs": [],
      "source": [
        "# check missing values in X_test\n",
        "\n",
        "X_test.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Scx2vuNwXa0"
      },
      "source": [
        "We can see that there are no missing values in X_train and X_test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWtdmeIJwXa0"
      },
      "source": [
        "### 9.4 Encode categorical variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnzJgc1dwXa0"
      },
      "outputs": [],
      "source": [
        "# preview categorical variables in X_train\n",
        "\n",
        "X_train[].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_6ADgaXwXa1"
      },
      "outputs": [],
      "source": [
        "# import category encoders\n",
        "\n",
        "import category_encoders as ce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_d1Co_hwXa1"
      },
      "outputs": [],
      "source": [
        "# encode categorical variables with one-hot encoding\n",
        "\n",
        "encoder = .OneHotEncoder(cols=[''])\n",
        "\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "\n",
        "X_test = encoder.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyjCmwvjwXa1"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03zd_gZkwXa1"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T6NxTomwXa1"
      },
      "outputs": [],
      "source": [
        "X_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9nLzgcXwXa2"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guzslLkTwXa2"
      },
      "source": [
        "* We now have training and testing set ready for model building. Before that, we should map all the feature variables onto the same scale. It is called **feature scaling**. We will do it as follows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHUP38sYwXa2"
      },
      "source": [
        "## 10. Feature Scaling <a class=\"anchor\" id=\"10\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEZkhIP2wXa2"
      },
      "outputs": [],
      "source": [
        "cols = X_train.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyqE-wo-wXa2"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "scaler = RobustScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ3qcxhrwXa2"
      },
      "outputs": [],
      "source": [
        "X_train = pd.DataFrame(X_train, columns=[cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxEZv1rWwXa2"
      },
      "outputs": [],
      "source": [
        "X_test = pd.DataFrame(X_test, columns=[cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV0DHcv8wXa2"
      },
      "source": [
        "We now have X_train dataset ready to be fed into the Random Forest classifier. We will do it as follows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0q2sXK6wXa3"
      },
      "source": [
        "## 11. Random Forest Classifier model with default parameters <a class=\"anchor\" id=\"11\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYf5Y56BwXa3"
      },
      "outputs": [],
      "source": [
        "# import Random Forest classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# instantiate the classifier \n",
        "rfc = (random_state=0)\n",
        "\n",
        "# fit the model\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "# Predict the Test set results\n",
        "y_pred = rfc.predict(X_test)\n",
        "\n",
        "# Check accuracy score \n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score with 10 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcwcyQ3QwXa3"
      },
      "source": [
        "Here, **y_test** are the true class labels and **y_pred** are the predicted class labels in the test-set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNHNbpDAwXa3"
      },
      "source": [
        "Here, We have build the Random Forest Classifier model with default parameter of `n_estimators = 10`. So, We have used 10 decision-trees to build the model. Now, We will increase the number of decision-trees and see its effect on accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI0T7bupwXa3"
      },
      "source": [
        "## 12. Random Forest Classifier model with 100 Decision Trees  <a class=\"anchor\" id=\"12\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMpf5xt7wXa3"
      },
      "outputs": [],
      "source": [
        "# instantiate the classifier with n_estimators = 10\n",
        "rfc_100 = (n_estimators=100, random_state=0)\n",
        "\n",
        "# fit the model to the training set\n",
        "rfc_100.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set results\n",
        "y_pred_100 = .predict(X_test)\n",
        "\n",
        "# Check accuracy score \n",
        "print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test, y_pred_100)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hxWtUnZDwXa3"
      },
      "source": [
        "The model accuracy score with 10 decision-trees is `[ANSWER HERE BASED ON YOUR RESULT]` but the same with 100 decision-trees is `[ANSWER HERE BASED ON YOUR RESULT]`. So, as expected accuracy increases with number of decision-trees in the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjHB9Le3wXa4"
      },
      "source": [
        "## 13. Find important features with Random Forest model <a class=\"anchor\" id=\"13\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALbPNLXpwXa4"
      },
      "outputs": [],
      "source": [
        "# create the classifier with n_estimators = 100\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "\n",
        "# fit the model to the training set\n",
        "clf.(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3YAJOKQwXa4"
      },
      "source": [
        "Now, We will use the feature importance variable to see feature importance scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALcxxg1swXa4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# view the feature scores\n",
        "feature_scores = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "\n",
        "feature_scores"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CWoqQoVOwXa5"
      },
      "source": [
        "We can see that the most important feature is `[ANSWER HERE BASED ON YOUR RESULT]` and least important feature is `[ANSWER HERE BASED ON YOUR RESULT]`."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NXK8xx2IwXa5"
      },
      "source": [
        "## 14. Build the Random Forest model on selected features <a class=\"anchor\" id=\"14\"></a>\n",
        "\n",
        "Now, We will drop the least important feature `[ANSWER HERE BASED ON YOUR RESULT]` from the model, rebuild the model and check its effect on accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbEG1V9NwXa6"
      },
      "outputs": [],
      "source": [
        "# drop the least important feature from X_train and X_test\n",
        "\n",
        "X_train = X_train.drop(['...'], axis=1)\n",
        "X_test = X_test.drop(['...'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KGPxzAEwXa6"
      },
      "source": [
        "Now, We will build the random forest model again and check accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtsiaS8YwXa6"
      },
      "outputs": [],
      "source": [
        "# instantiate the classifier with n_estimators = 100\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "# fit the model to the training set\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set results\n",
        "y_pred = clf.(X_test)\n",
        "\n",
        "# Check accuracy score \n",
        "print('Model accuracy score with ... variable removed : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bP__z0TwXa6"
      },
      "source": [
        "Now, based on the above analysis we can conclude that our classification model accuracy is very good. Our model is doing a very good job in terms of predicting the class labels.\n",
        "\n",
        "\n",
        "But, it does not give the underlying distribution of values. Also, it does not tell anything about the type of errors our classifer is making. \n",
        "\n",
        "\n",
        "We have another tool called `Confusion matrix` that comes to our rescue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB8z3HuMwXa6"
      },
      "source": [
        "## 15. Confusion matrix <a class=\"anchor\" id=\"15\"></a>\n",
        "\n",
        "A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n",
        "\n",
        "\n",
        "Four types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n",
        "\n",
        "\n",
        "**True Positives (TP)** – True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n",
        "\n",
        "\n",
        "**True Negatives (TN)** – True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n",
        "\n",
        "\n",
        "**False Positives (FP)** – False Positives occur when we predict an observation belongs to a    certain class but the observation actually does not belong to that class. This type of error is called **Type I error.**\n",
        "\n",
        "\n",
        "\n",
        "**False Negatives (FN)** – False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called **Type II error.**\n",
        "\n",
        "\n",
        "\n",
        "These four outcomes are summarized in a confusion matrix given below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aj2m8FLbwXa7"
      },
      "outputs": [],
      "source": [
        "# Print the Confusion Matrix and slice it into four pieces\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = _matrix(y_test, y_pred)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0Lc7SzxwXa7"
      },
      "outputs": [],
      "source": [
        "# visualize confusion matrix with seaborn heatmap\n",
        "\n",
        "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
        "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvOQbPSawXa7"
      },
      "source": [
        "## 16. Classification Report <a class=\"anchor\" id=\"16\"></a>\n",
        "\n",
        "**Classification report** is another way to evaluate the classification model performance. It displays the  **precision**, **recall**, **f1** and **support** scores for the model. We have described these terms in later.\n",
        "\n",
        "We can print a classification report as follows:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0VD6tb3wXa7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, ))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X5UdErH5SIt6"
      },
      "source": [
        "## Bonus Section\n",
        "\n",
        "Decision Tree Visualization\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "julia"
        }
      },
      "outputs": [],
      "source": [
        "# CODE HERE (For bonus section only)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
